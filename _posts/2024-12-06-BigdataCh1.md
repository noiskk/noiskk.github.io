---
layout: post
title: "[책] 빅데이터를 지탱하는 기술 _ ch1"
date: 2024-12-06 00:00:00 +0900
categories: book
---

#  **CH.1 빅데이터의 기초 지식** 
<br>

## **빅데이터의 정착**

2011년 이후 **'빅데이터'**가 본격적으로 등장했다. <br>

#### **빅데이터의 취급이 어려운 이유**
- 데이터의 분석 방법을 모른다.
- 데이터 처리에 수고와 시간이 걸린다. 

위 두가지 문제를 해결해야 비로소 가치 있는 정보를 얻을 수 있다. <br><br>

#### **기초 빅데이터 기술**
**Hadoop** 
- 다수의 컴퓨터에서 대량의 데이터 처리
  - 방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리할 수 있는 구조가 필요하다. 
  - 수백 ~ 수천 대 단위의 컴퓨터를 이용하여 위 작업을 관리하는 것이 Hadoop 이다. 

**NoSQL** 
- 빈번한 읽기/쓰기 및 분산 처리의 강점
  - **비관계형** 데이터베이스 (전통적인 RDB의 제약을 제거시킴)
  - key-value : 다수의 키와 값을 관련지어 저장한다.
  - document : JSON과 같은 복잡한 데이터 구조를 저장한다. 
  - wide-column : 여러 키를 사용하여 높은 확장성을 제공한다. 

**NoSQL + Hadoop 조합**
- **NoSQL** 데이터베이스에 기록하여 **Hadoop**으로 분산처리를 하는 흐름이다.
- 현실적인 비용으로 데이터를 처리할 수 있게 되었다.

<br>

## **빅데이터 시대의 데이터 분석 기반**



#### **데이터 파이프라인**
'차례대로 전달해나가는 데이터로 구성된 시스템'을 말한다.<br> 어디에서 데이터를 수집하여 무엇을 실현하고 싶은지에 따라 변화한다.<br> 간단한 구성으로 시작하지만 목적에 따라 점차 복잡해질 수 있다.

<br>
#### **데이터 수집**
데이터 파이프라인은 데이터를 모으는 부분부터 시작한다. <br> 데이터 전송 방식에 따라 **벌크**형과 **스트리밍**형으로 나눌 수 있다. 
- 벌크형 
  : 어딘가에 존재하는 데이터를 정리해 추출하는 방법 <br>데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데 사용된다.
- 스트리밍형 
  : 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법 <br> 모바일 앱, 임베디드 기계 등에서 발생하는 데이터를 수집하는 데 사용된다.

<img src="/assets/img/DataPipeline.png" alt="데이터 파이프라인" width="600" height="400">

<br>


#### **스트림 처리와 배치 처리**
**스트림 처리**
: 실시간 데이터를 시계열 데이터베이스에 저장해 처리하는 방법. <br> 일반적으로 단기적 데이터 처리를 취급한다.

**배치 처리**
: 어느정도 정리된 데이터를 한 번에 저장해 처리하는 방법. <br> 일반적으로 장기적 데이터 처리를 취급한다.

<br>

#### **분산 스토리지**
여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템
- 객체 스토리지
  : 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장하는 방법
- NoSQL 데이터베이스

<br>

#### **분산 데이터 처리**
분산 스토리지에 저장된 데이터를 처리하기 위해서는 **분산 데이터 처리 프레임워크**가 필요하다. <br>
  - 분산 데이터 처리로 데이터 가공 및 외부 데이터베이스에 저장의 역할을 수행한다. 
  - 빅데이터를 SQL로 집계하는 두 가지 방법
    - **쿼리 엔진 도입** : Hive. (현재는 대화형 쿼리 엔진도 개발되었다.)
    - **외부 데이터 웨어하우스 제품 이용** : AWS Redshift, Google BigQuery
      <br>이를 위해서는 분산 스토리지에서 추출한 데이터를 데이터 웨어하우스에 적합한 형식으로 변환해야 한다. 
      <br>이러한 절차가 **ETL(Extract - Transform - Load) 프로세스**

<br>

#### **워크플로 관리**
전체 데이터 파이프라인 동작의 관리를 위한 기술<br>
- 매일 정해진 시간에 배치 처리를 스케줄대로 실행
- 오류 발생 시 관리자에게 통지

<br>

#### **데이터 웨어하우스와 데이터 마트**
데이터 웨어하우스 (DW)
: **대량**의 데이터를 **장기 보존**할 수 있는 공간
  <br>정리된 데이터를 한 번에 전송하는 것은 뛰어나지만, 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않다.

데이터 마트 (DM)
: 데이터 웨어하우스에서 **데이터 분석**과 같은 목적에 **필요한 데이터만** 추출하여 구축한 것
  <br>BI 도구와 조합시키는 형태로 데이터를 시각화하는데 주로 사용된다. 

데이터 소스
: 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버

ETL 프로세스
: 데이터 소스에 보존된 원시 데이터를 추출해 필요에 따라 가공한 뒤 SQL을 활용해 DW에 저장하는 흐름 (DW 측면)

<img src="/assets/img/DataWarehouse.png" alt="데이터 웨어하우스와 데이터 마트" width="600" height="400">

<br>

#### **데이터 레이크와 데이터 마트**
빅데이터 시대에 모든 데이터가 DW를 가정해서 만들어지지는 않는다. <br>
모든 데이터를 원래의 형태로 축적해두고 나중에 그것을 필요에 따라 가공하는 구조가 필요하다.<br>
- 데이터 레이크 (DL)
: **원래의 형태**로 데이터를 저장하는 장소<br>
  DL은 단순한 스토리지로써 분산 데이터 처리 기술을 이용해야 데이터를 처리할 수 있다. 

<img src="/assets/img/DataLake.png" alt="데이터 레이크와 데이터 마트" width="600" height="400">

<br>

#### **데이터를 수집하는 목적** <br>
1. **데이터 검색**
  : 대량의 데이터 중에서 조건에 맞는 것을 찾고 싶은 경우<br>
    필요할 때 신속하게 검색할 수 있어야 하므로 시스템에는 실시간 데이터 처리나 검색 엔진을 사용하여 키워드를 찾는 기능이 필요하다.
2. **데이터 가공**
  : 업무 시스템의 일부로서 데이터 처리 결과를 이용하고 싶은 경우<br>
    데이터의 가공에는 자동화가 필수적이다. 워크플로 관리를 도입하여 시스템을 구축한다.
3. **데이터 시각화**
  : 데이터를 시각적으로 봄으로써 앞으로의 상황을 예측해 의사 결정에 도움이 되도록 하는 경우<br>
    고속화를 위해 데이터 마트가 필요하다. 

<br>

## **정리**
